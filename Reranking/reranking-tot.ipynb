{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10998655,"sourceType":"datasetVersion","datasetId":6846729},{"sourceId":11540126,"sourceType":"datasetVersion","datasetId":7237087},{"sourceId":11540517,"sourceType":"datasetVersion","datasetId":7237332},{"sourceId":11540582,"sourceType":"datasetVersion","datasetId":7237368},{"sourceId":11540766,"sourceType":"datasetVersion","datasetId":7237486},{"sourceId":11546451,"sourceType":"datasetVersion","datasetId":7240923}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install -q faiss-cpu sentence-transformers pytrec_eval torch tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:15:25.279468Z","iopub.execute_input":"2025-04-24T13:15:25.279936Z","iopub.status.idle":"2025-04-24T13:17:15.140259Z","shell.execute_reply.started":"2025-04-24T13:15:25.279901Z","shell.execute_reply":"2025-04-24T13:17:15.138324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"  # ✅ Disable WandB globally","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:15.144268Z","iopub.execute_input":"2025-04-24T13:17:15.145007Z","iopub.status.idle":"2025-04-24T13:17:15.153110Z","shell.execute_reply.started":"2025-04-24T13:17:15.144962Z","shell.execute_reply":"2025-04-24T13:17:15.151768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport logging\nimport json\nimport torch\nimport faiss\nimport numpy as np\nimport pytrec_eval\nfrom sentence_transformers import SentenceTransformer, losses\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:15.154399Z","iopub.execute_input":"2025-04-24T13:17:15.154745Z","iopub.status.idle":"2025-04-24T13:17:56.176626Z","shell.execute_reply.started":"2025-04-24T13:17:15.154721Z","shell.execute_reply":"2025-04-24T13:17:56.175680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enable logging\nlogging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s - %(message)s')\nlog = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:56.178660Z","iopub.execute_input":"2025-04-24T13:17:56.180111Z","iopub.status.idle":"2025-04-24T13:17:56.185090Z","shell.execute_reply.started":"2025-04-24T13:17:56.180081Z","shell.execute_reply":"2025-04-24T13:17:56.183843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set paths\nDATA_PATH = '/kaggle/input/trec2023/TREC2023 Data/TREC-ToT'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:56.186240Z","iopub.execute_input":"2025-04-24T13:17:56.186648Z","iopub.status.idle":"2025-04-24T13:17:56.276720Z","shell.execute_reply.started":"2025-04-24T13:17:56.186614Z","shell.execute_reply":"2025-04-24T13:17:56.275235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEV_QREL_PATH =('/kaggle/input/trec2023/TREC2023 Data/TREC-ToT/TREC-TOT/dev/qrel.txt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:56.278141Z","iopub.execute_input":"2025-04-24T13:17:56.279344Z","iopub.status.idle":"2025-04-24T13:17:56.298392Z","shell.execute_reply.started":"2025-04-24T13:17:56.279314Z","shell.execute_reply":"2025-04-24T13:17:56.297296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_qrels(qrel_file):\n    \"\"\"Load qrels (relevance judgments).\"\"\"\n    qrels = {}\n    with open(qrel_file, 'r', encoding='utf-8') as f:\n        for line in f:\n            qid, _, docid, rel = line.strip().split()\n            if qid not in qrels:\n                qrels[qid] = {}\n            qrels[qid][docid] = int(rel)\n    return qrels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:56.299652Z","iopub.execute_input":"2025-04-24T13:17:56.299965Z","iopub.status.idle":"2025-04-24T13:17:56.320111Z","shell.execute_reply.started":"2025-04-24T13:17:56.299940Z","shell.execute_reply":"2025-04-24T13:17:56.319060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation function\ndef evaluate(retrieved, qrels):\n    common_qids = set(retrieved.keys()) & set(qrels.keys())\n    if not common_qids:\n        log.warning(\"No overlapping queries between results and qrels\")\n        return {}\n\n    evaluator = pytrec_eval.RelevanceEvaluator(\n    {qid: qrels[qid] for qid in common_qids},\n    {'ndcg_cut_10',    # same as plain 'ndcg'\n      'ndcg_cut_100',\n      'ndcg_cut_1000',\n      'recip_rank',\n      'recall_3', 'recall_100', 'recall_1000',\n      'success_3', 'success_100', 'success_1000'}\n    )\n    \n    results = evaluator.evaluate({qid: retrieved[qid] for qid in common_qids})\n    \n    return {metric: np.mean([v[metric] for v in results.values()]) \n           for metric in results[next(iter(results))].keys()}\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:17:56.321240Z","iopub.execute_input":"2025-04-24T13:17:56.321597Z","iopub.status.idle":"2025-04-24T13:17:56.342500Z","shell.execute_reply.started":"2025-04-24T13:17:56.321555Z","shell.execute_reply":"2025-04-24T13:17:56.341335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/ce-reranked-results/CE-MiniLM-L6-v2.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Roberta Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:14:28.816613Z","iopub.execute_input":"2025-04-24T06:14:28.816956Z","iopub.status.idle":"2025-04-24T06:14:29.159884Z","shell.execute_reply.started":"2025-04-24T06:14:28.816931Z","shell.execute_reply":"2025-04-24T06:14:29.158954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/ce-reranked-results/CE-MiniLM-L6-v2.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('CE-MiniLM Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:15:29.360188Z","iopub.execute_input":"2025-04-24T06:15:29.360984Z","iopub.status.idle":"2025-04-24T06:15:29.584541Z","shell.execute_reply.started":"2025-04-24T06:15:29.360961Z","shell.execute_reply":"2025-04-24T06:15:29.583587Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/ce-minilm-20epoch/CE-MiniLM-L6-v2_20Epoch.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Roberta Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:38:06.413193Z","iopub.execute_input":"2025-04-24T06:38:06.414316Z","iopub.status.idle":"2025-04-24T06:38:06.507821Z","shell.execute_reply.started":"2025-04-24T06:38:06.414281Z","shell.execute_reply":"2025-04-24T06:38:06.507062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/monot5epoch20/monot5_resultsEpoch20.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Roberta Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:42:10.831462Z","iopub.execute_input":"2025-04-24T06:42:10.831820Z","iopub.status.idle":"2025-04-24T06:42:10.868522Z","shell.execute_reply.started":"2025-04-24T06:42:10.831788Z","shell.execute_reply":"2025-04-24T06:42:10.867738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/rrfepoch20/rrf_resultsepoch20.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Roberta Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T06:53:18.828052Z","iopub.execute_input":"2025-04-24T06:53:18.828498Z","iopub.status.idle":"2025-04-24T06:53:19.086368Z","shell.execute_reply.started":"2025-04-24T06:53:18.828469Z","shell.execute_reply":"2025-04-24T06:53:19.085437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/CE-MiniLM-L6-v2_30E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:18.491423Z","iopub.execute_input":"2025-04-24T13:19:18.492339Z","iopub.status.idle":"2025-04-24T13:19:18.525445Z","shell.execute_reply.started":"2025-04-24T13:19:18.492310Z","shell.execute_reply":"2025-04-24T13:19:18.524295Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/monot5_results_30E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:15.794393Z","iopub.execute_input":"2025-04-24T13:19:15.794790Z","iopub.status.idle":"2025-04-24T13:19:15.825412Z","shell.execute_reply.started":"2025-04-24T13:19:15.794764Z","shell.execute_reply":"2025-04-24T13:19:15.824499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/rrf_results_30E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:12.893834Z","iopub.execute_input":"2025-04-24T13:19:12.894694Z","iopub.status.idle":"2025-04-24T13:19:13.108174Z","shell.execute_reply.started":"2025-04-24T13:19:12.894664Z","shell.execute_reply":"2025-04-24T13:19:13.107067Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/CE-MiniLM-L6-v2_50E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:10.094051Z","iopub.execute_input":"2025-04-24T13:19:10.094370Z","iopub.status.idle":"2025-04-24T13:19:10.131447Z","shell.execute_reply.started":"2025-04-24T13:19:10.094347Z","shell.execute_reply":"2025-04-24T13:19:10.130310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/monot5_results_50E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:07.707336Z","iopub.execute_input":"2025-04-24T13:19:07.707711Z","iopub.status.idle":"2025-04-24T13:19:07.759945Z","shell.execute_reply.started":"2025-04-24T13:19:07.707686Z","shell.execute_reply":"2025-04-24T13:19:07.758973Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\n# load your reranker output\nwith open(\"/kaggle/input/5030e/rrf_results_50E.json\") as f:\n    reranked = json.load(f)\n\n# load your qrels into the same dict[qid]→{docid: relevance}\nqrels = load_qrels(DEV_QREL_PATH)\n\n# run exactly the same evaluate call\nscores = evaluate(reranked, qrels)\nprint('Reranked Scores')\n# print(scores)\nfor metric, value in scores.items():\n    print(f\"{metric}: {value:.6f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T13:19:02.730380Z","iopub.execute_input":"2025-04-24T13:19:02.730866Z","iopub.status.idle":"2025-04-24T13:19:03.027080Z","shell.execute_reply.started":"2025-04-24T13:19:02.730838Z","shell.execute_reply":"2025-04-24T13:19:03.026095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}