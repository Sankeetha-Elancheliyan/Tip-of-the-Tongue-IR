{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11063236,"sourceType":"datasetVersion","datasetId":6860859}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install dependencies\n!pip install -q faiss-cpu sentence-transformers pytrec_eval torch tqdm\n\nimport faiss\nimport numpy as np\nimport json\nimport torch\nfrom sentence_transformers import SentenceTransformer\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load preprocessed corpus\nPROCESSED_CORPUS_PATH = \"/kaggle/input/preprocessed-corpus/preprocessed_corpus.jsonl\"\n\ndef load_corpus(file_path):\n    \"\"\"Load the preprocessed corpus from JSONL file.\"\"\"\n    corpus = []\n    doc_ids = []\n    doc_texts = []\n    \n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            doc = json.loads(line)\n            corpus.append(doc)\n            doc_ids.append(doc[\"doc_id\"])\n            doc_texts.append(doc[\"text\"])\n    \n    return corpus, doc_ids, doc_texts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the corpus\ndocuments, doc_ids, doc_texts = load_corpus(PROCESSED_CORPUS_PATH)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Sentence Transformer model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate embeddings\nbatch_size = 32 if torch.cuda.is_available() else 16\ndoc_embeddings = []\nprint(\"Encoding documents...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in tqdm(range(0, len(doc_texts), batch_size)):\n    batch = doc_texts[i:i + batch_size]\n    embeddings = model.encode(batch, convert_to_tensor=False)\n    doc_embeddings.append(embeddings)\n\ndoc_embeddings = np.vstack(doc_embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build FAISS index\nembedding_dim = doc_embeddings.shape[1]\nindex = faiss.IndexFlatL2(embedding_dim)\nfaiss.omp_set_num_threads(4)  # Optimize for CPU\nindex.add(doc_embeddings)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the FAISS index and doc_ids\nFAISS_INDEX_PATH = \"/kaggle/working/faiss_index.bin\"\nDOC_IDS_PATH = \"/kaggle/working/doc_ids.npy\"\n\nfaiss.write_index(index, FAISS_INDEX_PATH)\nnp.save(DOC_IDS_PATH, np.array(doc_ids))\n\nprint(f\"FAISS index saved at: {FAISS_INDEX_PATH}\")\nprint(f\"Document IDs saved at: {DOC_IDS_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}